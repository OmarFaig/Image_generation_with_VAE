{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/TUM/05_projects/Image_generation_with_VAE/vae_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 2132\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 533\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 427\n",
      "    })\n",
      "})\n",
      "{'train': (2132, 1), 'test': (533, 1), 'validation': (427, 1)}\n",
      "{'train': (2132, 1), 'test': (533, 1)}\n",
      "{'train': (1705, 1), 'test': (427, 1)}\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"Karthik11232/human_face_generation\")\n",
    "#split the dataset \n",
    "train_test_set = ds['train'].train_test_split(test_size=0.2)\n",
    "train_val_set = train_test_set['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': train_test_set['train'],\n",
    "    'test': train_test_set['test'],\n",
    "    'validation': train_val_set['test']\n",
    "})\n",
    "print (ds)\n",
    "print(ds.shape)\n",
    "print(train_test_set.shape)\n",
    "print(train_val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets to disk\n",
    "output_dir = './human_face_generation_split'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to save images\n",
    "def save_images(dataset, split_name):\n",
    "    split_dir = os.path.join(output_dir, split_name)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, sample in enumerate(dataset):\n",
    "        #print(f'{idx} {sample[\"image\"]}')\n",
    "        image=sample[\"image\"]\n",
    "        #buf = io.BytesIO()\n",
    "        #image = Image.open(sample['image'])\n",
    "        #print(image)\n",
    "        #image.save(buf, 'jpeg')\n",
    "        image_path = os.path.join(split_dir, f'image_{idx}.png')\n",
    "        #print(image_path)\n",
    "\n",
    "        image.save(image_path,\"jpeg\")\n",
    "\n",
    "# Save each split\n",
    "save_images(ds['train'], 'train')\n",
    "save_images(ds['validation'], 'validation')\n",
    "save_images(ds['test'], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
